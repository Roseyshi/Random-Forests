{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84687482",
   "metadata": {},
   "source": [
    "### Import the required liraries as follows. We will import others as we move along"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9069767",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e306c2a4",
   "metadata": {},
   "source": [
    "### Importing the csv formatted data which is in github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4293c6ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotArea</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>138</td>\n",
       "      <td>1204000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>145</td>\n",
       "      <td>1274000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>152</td>\n",
       "      <td>1673000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>152</td>\n",
       "      <td>1232000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>152</td>\n",
       "      <td>1195600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LotArea  SalePrice\n",
       "0      138    1204000\n",
       "1      145    1274000\n",
       "2      152    1673000\n",
       "3      152    1232000\n",
       "4      152    1195600"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/Explore-AI/Public-Data/master/house_price_by_area.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8527e4c1",
   "metadata": {},
   "source": [
    "### The preprocessing we will need is scaling since our columns have different scales. Our data is generally clean hence no further preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07889a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaled = scaler.fit_transform(df)\n",
    "df_scaled = pd.DataFrame(scaled, columns = df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2408d0d",
   "metadata": {},
   "source": [
    "### We will use the default max_depth of none for our first random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "106f6b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(n_estimators = 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1566170e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0d875db",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['LotArea']]\n",
    "y = df['SalePrice']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6e4c5d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 422490886596.1823\n",
      "RMSE: 649992.9896515672\n",
      "R2_Score: 0.3203611544334456\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "print(\"MSE:\", mean_squared_error(y_test, predictions))\n",
    "print(\"RMSE:\", np.sqrt(mean_squared_error(y_test, predictions)))\n",
    "print(\"R2_Score:\", r2_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9327e4",
   "metadata": {},
   "source": [
    "### Now we want to understand how different values of n_estimators and max_depth will affect the prfromance of our model and identify best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9060d4f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   n_estimators  max_depth           RMSE  R2 Score\n",
      "0            50          5  595492.457032  0.429556\n",
      "1            50         10  642413.479872  0.336119\n",
      "2            50         15  645465.923451  0.329795\n",
      "3           100          5  595122.779201  0.430264\n",
      "4           100         10  636382.485503  0.348526\n",
      "5           100         15  639620.534238  0.341879\n",
      "6           150          5  596876.659637  0.426900\n",
      "7           150         10  637534.304175  0.346165\n",
      "8           150         15  640830.259738  0.339387\n"
     ]
    }
   ],
   "source": [
    "def evaluate_rf_performance(X_train, X_test, y_train, y_test, n_estimators, max_depth):\n",
    "    rf = RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth, random_state=42)\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_test)\n",
    "    rmse =np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    return rmse, r2\n",
    "results = []\n",
    "\n",
    "# Iterate over different values of n_estimators and max_depth\n",
    "for n_estimators in [50, 100, 150]:\n",
    "    for max_depth in [5, 10, 15]:\n",
    "        # Call function to evaluate performance\n",
    "        rmse, r2 = evaluate_rf_performance(X_train, X_test, y_train, y_test, n_estimators, max_depth)\n",
    "        # Append results to list\n",
    "        results.append({'n_estimators': n_estimators, 'max_depth': max_depth, 'RMSE': rmse, 'R2 Score': r2})\n",
    "\n",
    "# Create DataFrame from list of results\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62398af0",
   "metadata": {},
   "source": [
    "### From the above measures, n_estimators of 100 and max_depth of 5 gives us a lower RMSE and a higher R2_score. This means that approximately 43% of the variance in the dependent variable is explained by the independent variables in the model. Thus we would conclude that (100, 5) combination is more accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0902019",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
